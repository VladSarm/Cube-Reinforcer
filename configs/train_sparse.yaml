# Sparse REINFORCE: 7 cells (a..g), 6 actions (U/L/B), H fixed.
# Training and policy parameters. CLI args override these when provided.

policy:
  # Observation: sparse_state(7) + action_history_one_hot(4*6=24) -> input_dim=31
  input_dim: 19
  hidden_dim: 128
  action_dim: 6
  history_len: 2
  init_scale: 0.01

training:
  num_envs: 12
  episodes: 1000000
  scramble_steps: 6
  max_episode_steps: 30
  gamma: 1.0
  lr: 0.001
  save_every: 20000
  checkpoint_dir: checkpoints_sparse
  seed: null
  log_interval: 1000
  stats_window: 1000
